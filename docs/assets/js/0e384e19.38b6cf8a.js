"use strict";(self.webpackChunkkaito_website=self.webpackChunkkaito_website||[]).push([[976],{679:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/arch-e9962ff2a48619c51458ab0ac6bf3795.png"},1512:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>c,toc:()=>l});var r=t(4848),i=t(8453);const s={title:"Introduction",slug:"/"},o=void 0,c={id:"intro",title:"Introduction",description:"Retrieval-augmented generation (RAG) is live! - RagEngine support with LlamaIndex orchestration and Faiss as the default vectorDB, learn about recent updates here!",source:"@site/docs/intro.md",sourceDirName:".",slug:"/",permalink:"/kaito/docs/",draft:!1,unlisted:!1,editUrl:"https://github.com/kaito-project/kaito/tree/main/website/docs/intro.md",tags:[],version:"current",frontMatter:{title:"Introduction",slug:"/"},sidebar:"sidebar",next:{title:"Installation",permalink:"/kaito/docs/installation"}},a={},l=[{value:"Key Features",id:"key-features",level:2},{value:"Architecture",id:"architecture",level:2},{value:"Getting Started",id:"getting-started",level:2},{value:"Community",id:"community",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(n.admonition,{title:"What's NEW!",type:"info",children:[(0,r.jsxs)(n.p,{children:["Retrieval-augmented generation (RAG) is live! - RagEngine support with LlamaIndex orchestration and Faiss as the default vectorDB, learn about recent updates ",(0,r.jsx)(n.a,{href:"https://github.com/kaito-project/kaito/issues/734",children:"here"}),"!"]}),(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Latest Release:"})," July 2nd, 2025. KAITO v0.5.0."]}),(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"First Release:"})," Nov 15th, 2023. KAITO v0.1.0."]})]}),"\n",(0,r.jsxs)(n.p,{children:["KAITO is an operator that automates the AI/ML model inference or tuning workload in a Kubernetes cluster.\nThe target models are popular open-sourced large models such as ",(0,r.jsx)(n.a,{href:"https://huggingface.co/tiiuae",children:"falcon"})," and ",(0,r.jsx)(n.a,{href:"https://huggingface.co/docs/transformers/main/en/model_doc/phi3",children:"phi-3"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"key-features",children:"Key Features"}),"\n",(0,r.jsx)(n.p,{children:"KAITO has the following key differentiations compared to most of the mainstream model deployment methodologies built on top of virtual machine infrastructures:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Container-based Model Management"}),": Manage large model files using container images with an OpenAI-compatible server for inference calls"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Preset Configurations"}),": Avoid adjusting workload parameters based on GPU hardware with built-in configurations"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multiple Runtime Support"}),": Support for popular inference runtimes including ",(0,r.jsx)(n.a,{href:"https://github.com/vllm-project/vllm",children:"vLLM"})," and ",(0,r.jsx)(n.a,{href:"https://github.com/huggingface/transformers",children:"transformers"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Auto-provisioning"}),": Automatically provision GPU nodes based on model requirements"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Public Registry"}),": Host large model images in the public Microsoft Container Registry (MCR) when licenses allow"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Using KAITO, the workflow of onboarding large AI inference models in Kubernetes is largely simplified."}),"\n",(0,r.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,r.jsxs)(n.p,{children:["KAITO follows the classic Kubernetes Custom Resource Definition(CRD)/controller design pattern. Users manage a ",(0,r.jsx)(n.code,{children:"workspace"})," custom resource which describes the GPU requirements and the inference or tuning specification. KAITO controllers automate the deployment by reconciling the ",(0,r.jsx)(n.code,{children:"workspace"})," custom resource."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"KAITO architecture",src:t(679).A+"",width:"3072",height:"1537"})}),"\n",(0,r.jsx)(n.p,{children:"The above figure presents the KAITO architecture overview. Its major components consist of:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Workspace controller"}),": Reconciles the ",(0,r.jsx)(n.code,{children:"workspace"})," custom resource, creates ",(0,r.jsx)(n.code,{children:"machine"})," custom resources to trigger node auto provisioning, and creates the inference or tuning workload (",(0,r.jsx)(n.code,{children:"deployment"}),", ",(0,r.jsx)(n.code,{children:"statefulset"})," or ",(0,r.jsx)(n.code,{children:"job"}),") based on the model preset configurations."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Node provisioner controller"}),": The controller's name is ",(0,r.jsx)(n.em,{children:"gpu-provisioner"})," in ",(0,r.jsx)(n.a,{href:"https://github.com/Azure/gpu-provisioner/tree/main/charts/gpu-provisioner",children:"gpu-provisioner helm chart"}),". It uses the ",(0,r.jsx)(n.code,{children:"machine"})," CRD originated from ",(0,r.jsx)(n.a,{href:"https://sigs.k8s.io/karpenter",children:"Karpenter"})," to interact with the workspace controller. It integrates with Azure Resource Manager REST APIs to add new GPU nodes to the AKS or AKS Arc cluster."]}),"\n"]}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.a,{href:"https://github.com/Azure/gpu-provisioner",children:(0,r.jsx)(n.em,{children:"gpu-provisioner"})})," is an open sourced component. It can be replaced by other controllers if they support ",(0,r.jsx)(n.a,{href:"https://sigs.k8s.io/karpenter",children:"Karpenter-core"})," APIs."]})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"KAITO RAG architecture",src:t(4282).A+"",width:"2892",height:"2264"})}),"\n",(0,r.jsx)(n.p,{children:"The above figure presents the RAGEngine architecture overview consisting of:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"RAGEngine controller"}),": It reconciles the ",(0,r.jsx)(n.code,{children:"ragengine"})," custom resource, creating the ",(0,r.jsx)(n.code,{children:"RAG Service"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"RAG Service"}),": This is the service that offer Retrieval Augmented Generation support with LlamaIndex orchestration and leveraging FAISS as the vector DB.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Local Embedding"}),": An embedding model running locally to embed queries and documents within the vector db."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Remote Embedding"}),": An optional embedding model running remotely used to embed queries and documents within the vector db."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"FAISS"}),": ",(0,r.jsx)(n.a,{href:"https://github.com/facebookresearch/faiss",children:"Facebook AI Similarity Search"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["For more information on RAGEngine installation and usage, check the docs ",(0,r.jsx)(n.a,{href:"/kaito/docs/rag",children:"here"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"getting-started",children:"Getting Started"}),"\n",(0,r.jsxs)(n.p,{children:["\ud83d\udc49 To get started, please see the ",(0,r.jsx)(n.a,{href:"installation",children:"Installation Guide"}),"!"]}),"\n",(0,r.jsxs)(n.p,{children:["\ud83d\udc49 For a quick start tutorial, check out ",(0,r.jsx)(n.a,{href:"quick-start",children:"Quick Start"}),"!"]}),"\n",(0,r.jsx)(n.h2,{id:"community",children:"Community"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"GitHub"}),": ",(0,r.jsx)(n.a,{href:"https://github.com/kaito-project/kaito",children:"kaito-project/kaito"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Slack"}),": ",(0,r.jsx)(n.a,{href:"https://join.slack.com/t/kaito-z6a6575/shared_invite/zt-37gh89vw7-odHfqmPRc5oRnDG99SBJNA",children:"Join our community"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Email"}),": ",(0,r.jsx)(n.a,{href:"mailto:kaito-dev@microsoft.com",children:"kaito-dev@microsoft.com"})]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},4282:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/ragarch-26134b6419be2d0accd8eeedadb16d7e.svg"},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>c});var r=t(6540);const i={},s=r.createContext(i);function o(e){const n=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);